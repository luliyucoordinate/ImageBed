---
layout: post
title: Go语言分布式网络爬虫（0）
category : go
tags : [go]
stickie: true
date: 2019-6-24 00:00:00
---

学习了一段时间的`golang`了，我们准备通过`golang`完成一个爬虫任务，目标是**对58同城租房信息爬取**。

首先安装`gopm`

```shell
go get -v -u github.com/gpmgo/gopm
```

接着我们分析一下`58`同城的网页，我们首先可以在`https://www.58.com/changecity.html`链接中查看不同城市

<center class="half">
    <img src="https://raw.githubusercontent.com/wiki/luliyucoordinate/ImageBed/Tiny-Go-Spider/lesson1/2019_6_24_1.png" width="600">
</center>

我们任意选定一个城市，比如说`合肥`，会出现如下信息

<center class="half">
    <img src="https://raw.githubusercontent.com/wiki/luliyucoordinate/ImageBed/Tiny-Go-Spider/lesson1/2019_6_24_2.png" width="600">
</center>

然后我们点击`租房`就出现了相应`合肥`的租房信息

<center class="half">
    <img src="https://raw.githubusercontent.com/wiki/luliyucoordinate/ImageBed/Tiny-Go-Spider/lesson1/2019_6_24_3.png" width="600">
</center>

然后我们点击第一个租房链接

<center class="half">
    <img src="https://raw.githubusercontent.com/wiki/luliyucoordinate/ImageBed/Tiny-Go-Spider/lesson1/2019_6_24_4.png" width="500">
</center>

爬虫实际上就是在模拟我们这一系列的点击操作。好，那我们这一小节的主要任务是

<center class="half">
      <img src="https://raw.githubusercontent.com/wiki/luliyucoordinate/ImageBed/Tiny-Go-Spider/lesson2/2019_6_24_1.png" width="300">
  </center>

新建一个工程，例如`Tiny-Go-Spider`，然后创建第一个包`crawler`

<center class="half">
    <img src="https://raw.githubusercontent.com/wiki/luliyucoordinate/ImageBed/Tiny-Go-Spider/lesson1/2019_6_24_5.png" width="300">
</center>

```go
func main() {
	res, err := http.Get("https://www.58.com/changecity.html")

	if err != nil {
		panic(err)
	}

	defer res.Body.Close()

	if res.StatusCode != http.StatusOK {
		fmt.Println("Error: status code", res.StatusCode)
		return
	}

	all, err := ioutil.ReadAll(res.Body)
	if err != nil {
		panic(err)
	}
	fmt.Printf("%s\n", all)
}
```

我们成功的打印了如下信息

<center class="half">
    <img src="https://raw.githubusercontent.com/wiki/luliyucoordinate/ImageBed/Tiny-Go-Spider/lesson1/2019_6_24_6.png" width="600">
</center>

如果我们获取的网页不是`utf-8`怎么办？我们需要一种通用的处理方法，`go`语言非常方便，我们可以安装

```shell
gopm get -g -v golang.org/x/text
gopm get -g -v golang.org/x/net/html
```

好的现在我们就可以识别网页的编码，然后编码转换，具体操作如下

```go
func determineEncoding(r io.Reader) encoding.Encoding {
	bytes, err := bufio.NewReader(r).Peek(1024)

	if err != nil {
		panic(err)
	}
	e, _, _ := charset.DetermineEncoding(bytes, "")
	return e
}
func main() {
    ...
    b, err := ioutil.ReadAll(res.Body)
	if err != nil {
		panic(err)
	}

	e := determineEncoding(bytes.NewReader((b)))
	utf8Reader := transform.NewReader(bytes.NewReader(b), e.NewDecoder())
	all, err := ioutil.ReadAll(utf8Reader)
	if err != nil {
		panic(err)
	}
	fmt.Printf("%s\n", all)
}
```

接着我们需要完成挑选城市的功能。我们这里使用正则表达式解析，我们发现输出的城市开头分别在`provinceList`、`independentCityList`和`cityList`这三个块中。我们可以这样子做

```go
func printCityList(contents []byte) {
	provinceList := make([]string, 0)

	re := regexp.MustCompile(`provinceList = {([^}]*)`)
	matches := re.FindAllSubmatch(contents, -1)
	for _, m := range matches {
		for _, subMatch := range m[1:] {
			str := strings.Replace(string(subMatch), " ", "", -1)
			str = strings.Replace(str, "\n", "", -1)
			for _, sub := range strings.FieldsFunc(str, splitByComma) {
				provinceList = append(provinceList, strings.Trim(strings.FieldsFunc(sub, splitBySemi)[0], `"`))
			}
		}
	}
...
}
func splitByComma(s rune) bool {
	if s == ',' {
		return true
	}
	return false
}

func splitBySemi(s rune) bool {
	if s == ':' {
		return true
	}
	return false
}
```

结果和我们预想的一致

<center class="half">
    <img src="https://raw.githubusercontent.com/wiki/luliyucoordinate/ImageBed/Tiny-Go-Spider/lesson1/2019_6_24_7.png" width="600">
</center>

至此我们第一小节的内容完成，我们提交代码到`github`。

**如果你觉得上述过程对你有一点困难，没关系，可以查看我的[Tiny-Go-Crawler lesson1](https://github.com/luliyucoordinate/Tiny-Go-Crawler/tree/master/lesson1)代码。**

**如有问题，希望大家指出！！！**
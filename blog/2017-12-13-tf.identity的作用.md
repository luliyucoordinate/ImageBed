---
layout: post
title: tf.identity的作用
category : 机器学习
tags : [identity, python, tensorflow]
stickie: true
---

还是从一个[例子](https://stackoverflow.com/questions/34877523/in-tensorflow-what-is-tf-identity-used-for)开始讲起

```python
x = tf.Variable(0.0)
x_plus_1 = tf.assign_add(x, 1)#对x进行加1操作
#tf.control_dependencies的作用是:在执行y=x前，先执行x_plus_1
with tf.control_dependencies([x_plus_1]):
    y = x
init = tf.initialize_all_variables()

with tf.Session() as session:
    init.run()
    for i in xrange(5):
        print(y.eval())
```

这个代码的输出和我们想象的不一样，他的输出是`0, 0, 0, 0, 0`

```python
x = tf.Variable(0.0)
x_plus_1 = tf.assign_add(x, 1)

with tf.control_dependencies([x_plus_1]):
    y = tf.identity(x)
init = tf.initialize_all_variables()

with tf.Session() as session:
    init.run()
    for i in xrange(5):
        print(y.eval())
```

这段代码的输出才是`1, 2, 3, 4, 5`

~~其实这里的`tf.identity`的作用相当于一个`reference`，也就是`y`仅仅是一个`x`的别名，这两个变量使用的是一块内存，而对于`y=x`，`x`与`y`在不同的内存中。~~

~~这里举一个经典的例子~~


~~这里的`swap1`就相当于没有加`tf.identity`的做法，而`swap2`就相当于加了`tf.identity`的做法。~~

~~虽然y=x这样做了，但是这里的`y`可以了理解为上面`swap1`中的`y`，他仅仅是一个局部变量，函数结束，这块内存就释放了。如果添加了`tf.identity`，也就是说，`y`相当于一个全局变量`x`的`reference`，修改`x`自然会修改`y`。~~

上面的论述存在一些问题，谢谢[JepsonWong](http://blog.csdn.net/u013710265)的指出。我后来去查看了`tensorflow`的源码，发现

```c++
void TF_ImportGraphDefOptionsAddReturnOutput(TF_ImportGraphDefOptions* opts,
…	
	  for (const tensorflow::Operation& op : control_deps) {
	    opts.control_dependencies.push_back(op.node()->name());
	  }
```

实际上，这里`tf.control_dependencies`在调用时，就是将`tensorflow::Operation`对象插入到`opts`链表里面。然而`y = x`操作不是一个`tensorflow::Operation`对象，所以第一个`tf.control_dependencies`并不会做插入操作。

而`tf.identity`的作用实际上，是将CPU操作转化为GPU操作，也就是一个`tensorflow::Operation`对象。具体上是说，`identity`返回了一个`Output`类型，而`Output`又是一种`Operation`。

当然这是我的理解，可能有不对之处，欢迎大家指出！
---
layout: post
title: Go语言分布式网络爬虫（1）
category : go
tags : [go]
stickie: true
date: 2019-6-24 00:00:00
---

我们的爬虫主体框架思路如下

- 获取`request`，将`request`发送给`engine`处理
- `engine`将`url`发送给`Fetcher`，`Fetcher`获取网页信息
- `Fetcher`获取网页信息后，发回`engine`
- `engine`将网页信息发送给`Parser`处理

这一小节的主要内容是对我们之前编写的代码进行一些简单的封装，并且编写部分`engine`和`parser`的代码。下面的总体的结构图

<center class="half">
    <img src="https://raw.githubusercontent.com/wiki/luliyucoordinate/ImageBed/Tiny-Go-Spider/lesson2/2019_6_24_5.png" width="300">
</center>

我们首先将之前`main`中的业务逻辑封装到`Fetch`函数中，我们需要建立一个新的包`fetcher`

<center class="half">
    <img src="https://raw.githubusercontent.com/wiki/luliyucoordinate/ImageBed/Tiny-Go-Spider/lesson2/2019_6_24_1.png" width="300">
</center>

```go
// fetcher/fetcher.go
func Fetch(url string) ([]byte, error) {
...
	if res.StatusCode != http.StatusOK {
		return nil, fmt.Errorf("wrong status code: %d", res.StatusCode)
	}

	b, err := ioutil.ReadAll(res.Body)
	if err != nil {
		return nil, fmt.Errorf("wrong status code: %s", err)
	}
...
}

func determineEncoding(r io.Reader) encoding.Encoding {
...
	if err != nil {
		log.Printf("Fetcher error: %v", err)
		return unicode.UTF8
	}
...
}
```

接着我们就要开始编写`engine`，首先建立一个`engine`的包，然后建立一个`types`文件

<center class="half">
    <img src="https://raw.githubusercontent.com/wiki/luliyucoordinate/ImageBed/Tiny-Go-Spider/lesson2/2019_6_24_3.png" width="300">
</center>

```go
// engine/types.go
type Request struct {
	Url string
	ParserFunc func([]byte) ParseResult
}

type ParseResult struct {
	Requests []Request
	Items []interface{}
}
```

接着我们就要开始编写`parser`，由于我们是建立**58同城**的`parser`，所以我们新建立一个`58`的包，然后再添加`parser`，建立文件`citylist.go`，用于处理城市列表信息


<center class="half">
    <img src="https://raw.githubusercontent.com/wiki/luliyucoordinate/ImageBed/Tiny-Go-Spider/lesson2/2019_6_24_2.png" width="300">
</center>

为了测试的必要，我们建立一个空的`url`处理函数

```go
// engine/types.go
func NilParser([]byte) ParseResult {
	return  ParseResult{}
}
```

将之前`printCityList`函数中的代码封装到`ParseCityList`函数中。

```go
// 58/parser/citylist.go
func ParseCityList(contents []byte) engine.ParseResult {
	result := engine.ParseResult{}

	re = regexp.MustCompile(`independentCityList = {([^}]*)`)
	matches = re.FindAllSubmatch(contents, -1)
	for _, m := range matches {
		for _, subMatch := range m[1:] {
			str := strings.Replace(string(subMatch), " ", "", -1)
			str = strings.Replace(str, "\n", "", -1)
			for _, sub := range strings.FieldsFunc(str, splitByComma) {
				...
				independentCityAbUrl := "https://" + independentCityAb + ".58.com"
				result.Items = append(result.Items, independentCity)
				result.Requests = append(result.Requests, engine.Request{
					Url:independentCityAbUrl,
					ParserFunc: engine.NilParser,
				})
			}
		}
	}

...
	return result
}
```

接着在`engine`包中建立`engine.go`文件，我们先写一个`Run`函数，用来处理接收到的`Request`。

```go
// engine/engine.go
func Run(seeds ...Request) {
	var requests []Request
	for _, r := range seeds {
		requests = append(requests, r)
	}

	for len(requests) > 0 {
		r := requests[0]
		requests = requests[1:]

		log.Printf("Fetching %s", r.Url)
		body, err := fetcher.Fetch(r.Url)
		if err != nil {
			log.Printf("Fetcher: error fetching url %s: %v", r.Url, err)
			continue
		}

		parseResult := r.ParserFunc(body)
		requests = append(requests, parseResult.Requests...)

		for _, item := range parseResult.Items {
			log.Printf("Got item %v", item)
		}
	}
}
```

修改一下我们的`main.go`

```go
func main() {
	engine.Run(engine.Request{
		Url:"https://www.58.com/changecity.html",
		ParserFunc: parser.ParseCityList,
	})
}
```

最后我们运行一下代码

<center class="half">
    <img src="https://raw.githubusercontent.com/wiki/luliyucoordinate/ImageBed/Tiny-Go-Spider/lesson2/2019_6_24_4.png" width="400">
</center>

接着我们需要编写我们`citylist.go`文件的测试文件`citylist_test.go`，首先需要将我们访问的网页`https://www.58.com/changecity.html`内容存为`html`文件，方便我们的测试

<center class="half">
    <img src="https://raw.githubusercontent.com/wiki/luliyucoordinate/ImageBed/Tiny-Go-Spider/lesson2/2019_6_24_6.png" width="400">
</center>

接着编写测试函数`TestParseCityList`

```go
func TestParseCityList(t *testing.T) {
	contents, err := fetcher.Fetch("https://www.58.com/changecity.html")
	if err != nil {
		panic(err)
	}

	result := ParseCityList(contents)

	const resultSize = 689
	expectedUrls := []string {
		"https://bj.58.com", "https://sh.58.com", "https://tj.58.com",
	}
	expectedCities := []string {
		"北京", "上海", "天津",
	}
	if len(result.Requests) != resultSize {
		t.Errorf("result should have %d requests; but had %d", resultSize, len(result.Requests))
	}
	for i, url := range expectedUrls {
		if result.Requests[i].Url != url {
			t.Errorf("expected url #%d: %s; but was %s", i, url, result.Requests[i].Url)
		}
	}

	if len(result.Items) != resultSize {
		t.Errorf("result should have %d requests; but had %d", resultSize, len(result.Items))
	}
	for i, city := range expectedCities {
		if result.Items[i].(string) != city {
			t.Errorf("expected city #%d: %s; but was %s", i, city, result.Items[i].(string))
		}
	}
}
```

测试结果如下

<center class="half">
    <img src="https://raw.githubusercontent.com/wiki/luliyucoordinate/ImageBed/Tiny-Go-Spider/lesson2/2019_6_24_7.png" width="400">
</center>

至此我们这一小节的内容完成，我们提交代码到`github`。

**如果你觉得上述过程对你有一点困难，没关系，可以查看我的[Tiny-Go-Crawler lesson2](https://github.com/luliyucoordinate/Tiny-Go-Crawler/tree/master/lesson2)代码。**

**如有问题，希望大家指出！！！**
---
layout: post
title: Go语言分布式网络爬虫（4）
category : go
tags : [go]
stickie: true
date: 2019-7-1 00:00:00
---

从本小结开始我们需要将我们的爬虫优化为高并发的版本。首先看一下我们的结构

1

我们现将`engine`中的获取网页部分代码封装成`worker`，因为获取网页的时间是比较长的，我们希望通过`goruntine`来解决这个问题。

```go
// engine/engine.go
func Run(seeds ...Request) {
	...
	for len(requests) > 0 {
		r := requests[0]
		requests = requests[1:]

		parseResult, err := worker(r)
		...
	}
}

func worker(r Request) (ParseResult, error) {
	log.Printf("Fetching %s", r.Url)
	body, err := fetcher.Fetch(r.Url)
	ParseHtmlWithFont(&body)
	if err != nil {
		log.Printf("Fetcher: error fetching url %s: %v", r.Url, err)
		return ParseResult{}, err
	}

	return r.ParserFunc(body), nil
}
```

有代码的继续优化，我们现在的`engine.go`已经不够用来，我们现将其命名更变为`simple.go`，同时稍微改一下代码

```go
type SimpleEngine struct {}

func (e SimpleEngine) Run(seeds ...Request) {
    ...
}
```

接着我们创建一个新的`engine`，我们命名为`concorrent.go`

首先我们在`engine`的目录下，新建文件`concurrent.go`

2

```go
// engine/concurrent.go
type ConcurrentEngine struct {
	Scheduler Scheduler
	WorkerCount int
}

type Scheduler interface {
	Submit(Request)
	ConfigureMasterWorkerChan(chan Request)
}

func (e *ConcurrentEngine) Run(seeds ...Request) {
	in := make(chan Request)
	out := make(chan ParseResult)
	e.Scheduler.ConfigureMasterWorkerChan(in)
	for i := 0; i < e.WorkerCount; i++ {
		createWorker(in, out)
	}

	for _, r := range seeds {
		e.Scheduler.Submit(r)
	}

	for {
		result := <- out
		for _, item := range result.Items {
			log.Printf("Got item: %v", item)
		}

		for _, request := range result.Requests {
			e.Scheduler.Submit(request)
		}
	}
}

func createWorker(in chan Request, out chan ParseResult) {
	go func() {
		for {
			request := <- in
			result, err := worker(request)
			if err != nil {
				continue
			}
			out <- result
		}
	} ()
}
```

接着我们就需要编写一种调度策略，来将我们的`request`发给不同的`worker`。一种偷懒的实现方式就是将所有的`request`发送到一个`channel`中，然后不同的`worker`去竞争`request`。

3

```go
// scheduler/simple.go
type SimpleScheduler struct {
	workerChan chan engine.Request
}

func (s *SimpleScheduler) Submit(r engine.Request) {
	s.workerChan <- r
}

func (s *SimpleScheduler) ConfigureMasterWorkerChan(c chan engine.Request) {
	s.workerChan = c
}
```

现在只需要将我们的`main.go`稍加修改即可

```go
// main.go
func main() {
	e := engine.ConcurrentEngine{
		Scheduler: &scheduler.SimpleScheduler{},
		WorkerCount: 10,
	}

	e.Run(engine.Request{
		Url:"https://www.58.com/changecity.html",
		ParserFunc: parser.ParseCityList,
	})
}
```

结果工作的非常不错

4

但是上面的代码实际上是会造成死锁的，问题就出在`createWorker`上面

```go
// engine/concurrent.go
func createWorker(in chan Request, out chan ParseResult) {
	go func() {
		for {
			request := <- in
			result, err := worker(request)
			if err != nil {
				continue
			}
			out <- result
		}
	} ()
}
```

如果我们所有的`worker`都在工作，这个时候如果有`request`的话，就没有`worker`去接收了，那么就没有`worker`送出`result`

**如果你觉得上述过程对你有一点困难，没关系，可以查看我的[Tiny-Go-Crawler lesson4](https://github.com/luliyucoordinate/Tiny-Go-Crawler/tree/master/lesson4)代码。**

**如有问题，希望大家指出！！！**
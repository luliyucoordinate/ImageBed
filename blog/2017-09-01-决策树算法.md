---
layout: post
title: 决策树算法
category : 机器学习
tags : [机器学习, 决策树算法]
stickie: true
---

评定一个算法的好坏的标准：

准确率  速度  强壮性  可规模性  可解释性

 

Decision tree:
---

判断树是一个类似与流程图的树结构，其中内部结点表示在一个属性上的测试，每个分支代表一个属性输出，而每个树叶节点代表类和类分布。树的最顶层是根节点。

熵（entropy）概念：

信息量的度量就等于不确定性的多少。变量的不确定性越大，熵也就越大



决策树归纳算法（ID3）

选择属性判断节点

信息获取量（information Gain）：Gain(A) = Info(D) - Info_A(D)没有A时的信息量-增加A时的信息量。对于连续性数据的处理，就是把它变成离散化。

 

其他算法：

C4.5：QuinLan

Classification and Regression Trees（CART）

共同点：都是贪心算法，自上而下（Top-down approach）

区别：属性选择度量方法不同：C4.5(gain ratio)，CART(gini index)，ID3(Information Gain)

 

剪枝（避免overfitting）

分的太细了

有两种方案：先剪枝，后剪枝

 

决策树优点：直观，便于理解，小规模数据集有效

决策树缺点：处理连续性变量不好，类别较多时，错误增加的比较快，可规模性一般



决策树的应用
---

Python机器学习的库scikit-learn

覆盖领域：

分类（classification） 回归（regression） 聚类（clustering） 降维（dimensionality reduction） 

模型选择（model selection）

预处理（preprocessing）

使用scikit-learn

安装scikit-learn：pip

安装必要的package：numpy，scipy和matplotlib，可使用anaconda

测试数据

| RID  | age         | income | student | credit_rating | Class_buys_computer |
| ---- | ----------- | ------ | ------- | ------------- | ------------------- |
| 1    | youth       | high   | no      | fair          | no                  |
| 2    | youth       | high   | no      | excellent     | no                  |
| 3    | middle_aged | high   | no      | fair          | yes                 |
| 4    | senior      | medium | no      | fair          | yes                 |
| 5    | senior      | low    | yes     | fair          | yes                 |
| 6    | senior      | low    | yes     | excellent     | no                  |
| 7    | middle_aged | low    | yes     | excellent     | yes                 |
| 8    | youth       | medium | no      | fair          | no                  |
| 9    | youth       | low    | yes     | fair          | yes                 |
| 10   | senior      | medium | yes     | fair          | yes                 |
| 11   | youth       | medium | yes     | excellent     | yes                 |
| 12   | middle_aged | medium | no      | excellent     | yes                 |
| 13   | middle_aged | high   | yes     | fair          | yes                 |
| 14   | senior      | medium | no      | excellent     | no                  |

测试代码

```python
'''
Created on Sep 1, 2017

@author: coordinate
'''
#coding:utf-8
from sklearn.feature_extraction import DictVectorizer
import csv
from sklearn import preprocessing
from sklearn.externals.six import StringIO
from sklearn import tree

allElectronicData = open(r'D:\eclipse workspace\DeepLearningBasicsMachineLearning\AllElectronic.csv')
reader = csv.reader(allElectronicData) #read by line
headers = reader.next()

print(headers)
featureList = []
labelList = []

for row in reader:
    labelList.append(row[len(row) - 1])
    rowDict = {}
    for i in range(1, len(row) - 1):
        rowDict[headers[i]] = row[i]
    featureList.append(rowDict)
print(featureList)

vec = DictVectorizer()
dummyX = vec.fit_transform(featureList).toarray()

print("dummyX:" +str(dummyX))
print(vec.get_feature_names())

print("labelList: " + str(labelList))

lb = preprocessing.LabelBinarizer()
dummyY = lb.fit_transform(labelList)
print("dummyY: " + str(dummyY))

clf = tree.DecisionTreeClassifier(criterion = 'entropy')
clf = clf.fit(dummyX, dummyY)
print("clf: " + str(clf))

with open("allElectronicInformationGainOri.dot", 'w') as f:
    f = tree.export_graphviz(clf, feature_names=vec.get_feature_names(), out_file = f)

#predict
oneRowX = dummyX[0, :]
print("oneRowX: " + str(oneRowX))

newRowX = oneRowX
newRowX[0] = 1
newRowX[1] = 0
print("newRowX: " + str(newRowX))

predictedY = clf.predict(newRowX)
print("predictedY:" +str(predictedY))
```

 测试结果

<a href="http://wx4.sinaimg.cn/mw690/af2d2659ly1fj4ap3pxvfj20r80mm419.jpg" data-lightbox="roadtrip">
<img src="http://wx4.sinaimg.cn/mw690/af2d2659ly1fj4ap3pxvfj20r80mm419.jpg" class="img-fluid">
</a>
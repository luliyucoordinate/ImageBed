---
layout: post
title: 目标检测中的IOU计算问题
category : 机器学习
tags : [IOU, python, c]
stickie: true
---

在目标检测中我们有一个基本的操作，形象表述就是画框框，我们要通过我们画的框把我们要标注的目标给框出来，如下面那个狗。我们既可以说这个狗被框出来了，但是也可以说没有，因为你可以观察到左边和上面是存在一些缝隙的。

<center class="half">
<img src="https://raw.githubusercontent.com/wiki/luliyucoordinate/ImageBed/iou/2019_6_15_1.jpg"  width="350" height="300">
</center>

那问题就出现了。什么样的框才算把目标给框住了呢？这个时候就有了IOU这个评价指标。什么是IOU？

<center class="half">
<img src="https://raw.githubusercontent.com/wiki/luliyucoordinate/ImageBed/iou/2019_6_15_2.jpg"  width="350" height="300">
</center>

IOU想要描述的时黄框（检测到的结果）和绿框（标注的结果）重合的程度。用公式表示为

- $IOU = \frac{DetectionResult\bigcap GroundTruth}{DetectionResult\bigcup GroundTruth}$

公式里面的`DetectionResult`就表示黄框（也就是通过神经网络得到的结果），`GroundResult`表示绿框（也就是标注的结果）。

好的，这看上去很容易，但是在具体实现的时候就会有一些问题了。接下来我先用YOLO2中的做法讲解其实现原理。

```c
float overlap(float x1, float w1, float x2, float w2)
{
    float l1 = x1 - w1/2;
    float l2 = x2 - w2/2;
    float left = l1 > l2 ? l1 : l2;
    float r1 = x1 + w1/2;
    float r2 = x2 + w2/2;
    float right = r1 < r2 ? r1 : r2;
    return right - left;
}

float box_intersection(box a, box b)
{
    float w = overlap(a.x, a.w, b.x, b.w);
    float h = overlap(a.y, a.h, b.y, b.h);
    if(w < 0 || h < 0) return 0;
    float area = w*h;
    return area;
}

float box_union(box a, box b)
{
    float i = box_intersection(a, b);
    float u = a.w*a.h + b.w*b.h - i;
    return u;
}
float box_iou(box a, box b)
{
    return box_intersection(a, b)/box_union(a, b);
}
```

在这个代码中`box a`表示结果`box`，而`box b`表示的是标注`box`，这两者都是`box`类的对象，这个类在这里我们用到了这样几个属性：

- `x`:表示box中心点的x坐标
- `y`:表示box中心点的y坐标
- `w`:表示box的宽度
- `h`:表示box的高度

我么先看第一个函数`overlap`是干什么的。假设按照`box_intersection`中的第一个做法，传入这样几个参数`overlap(a.x, a.w, b.x, b.w)`，结果就是`l1`表示黄框的左边，`l2`表示绿框的左边，`r1`表示黄框的右边，`r2`表示绿框的右边。如下图

<center class="half">
<img src="https://raw.githubusercontent.com/wiki/luliyucoordinate/ImageBed/iou/2019_6_15_3.jpg"  width="350" height="300">
</center>

接着`left=l2`，`right=r1`，最后`right-left=交集的宽`。同理传入`overlap(a.y, a.h, b.y, b.h)`

得到交集的高。两个一乘即为交集的大小。`box_iou`函数中的做法大家应该可以看得明白了，不再赘述。

当我们训练好网络后，将待测图像输入网络得到的输出结果是一个高维矩阵。在YOLO2中最后得到的矩阵是这样的`[-1, H, W, B, (4 + 1 + C)]`。

- `H`:表示纵向分割的块的数目
- `W`:表示横向分割的块的数目

也就是一幅图片被我们分割为了`H*W`块。

- `B`:表示anchors的数目
- `C`:表示classes的数目

注意这里的`4`表示前面讲的`x,y,w,h`，而后面`1`表示`confidence`（参看论文中的$Pr(object)*IOU$）

以下是对应的python tensorflow版本

```python
coords = tf.reshape(coords, [-1, H*W, B, 4])
wh = tf.exp(coords[:,:,:,2:4]) * np.reshape(anchors, [1, 1, B, 2])
area_pred = wh[:,:,:,0] * wh[:,:,:,1]#得到预测框的面积
centers = coords[:,:,:,0:2]#得到预测框的xy
floor = centers - (wh * .5)
ceil  = centers + (wh * .5)

# calculate the intersection areas
intersect_upleft   = tf.maximum(floor, _upleft)
intersect_botright = tf.minimum(ceil , _botright)
intersect_wh = intersect_botright - intersect_upleft
intersect_wh = tf.maximum(intersect_wh, 0.0)
intersect = tf.multiply(intersect_wh[:,:,:,0], intersect_wh[:,:,:,1])#得到交集

# calculate the best IOU, set 0.0 confidence for worse boxes
iou = tf.truediv(intersect, _areas + area_pred - intersect)#_areas表示真实的面积
```

这里的`floor`对应于上面的`l1`、黄框的下边，`ceil`对应于上面的`r1`、黄框的上边。`_upleft`对应上面的`l2`和绿框的下边，`_botright`对应上面的`r2`和绿框的上边。`intersect_upleft`就是`l2`和黄框的下边，`intersect_botright`就是`r1`和绿框的上边，后面的代码就顺理成章了。

由于本人水平有限，如有问题，恳请指出！^_^